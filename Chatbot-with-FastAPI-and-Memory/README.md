# ğŸ¤– Chatbot with FastAPI & Memory  

A simple yet powerful chatbot application built with **FastAPI (backend)** and **Streamlit (frontend)**.  
It uses **session memory** to store conversation history, making interactions more natural and context-aware.  

---

```
## ğŸ“‚ Project Structure  

Chatbot-with-FastAPI-and-Memory/
â”‚
â”œâ”€â”€ Backend/
â”‚ â”œâ”€â”€ app.py â†’ Main FastAPI app (entry point for backend server)
â”‚ â”œâ”€â”€ chatbot.py â†’ Handles chatbot logic (calls LLM API, processes response)
â”‚ â”œâ”€â”€ memory.py â†’ Stores conversation history (session memory)
â”‚ â””â”€â”€ models.py â†’ Defines request/response data structures (Pydantic models)
â”‚
â”œâ”€â”€ Frontend/
â”‚ â””â”€â”€ frontend.py â†’ Simple frontend (Streamlit) to chat with backend
â”‚
â”œâ”€â”€ .env â†’ Stores API keys & secrets (not shared publicly)
â”œâ”€â”€ .gitignore â†’ Ignore files like .env, venv/, __pycache__/
â”œâ”€â”€ README.md â†’ Project documentation
â””â”€â”€ requirements.txt â†’ Python dependencies

---

## ğŸš€ Features  

- âš¡ **FastAPI Backend** â†’ Handles chatbot API requests efficiently.  
- ğŸ’¬ **Session Memory** â†’ Remembers previous messages in the conversation.  
- ğŸ¨ **Frontend (Streamlit)** â†’ Clean UI to interact with the chatbot.  
- ğŸ”’ **Environment Variables** â†’ Securely store API keys in `.env`.  
- ğŸ“¦ **Modular Code** â†’ Separate files for models, memory, chatbot logic.  

---

## ğŸ› ï¸ Installation  
1ï¸âƒ£ Clone the Repository  
bash
git clone https://github.com/your-username/Chatbot-with-FastAPI-and-Memory.git
cd Chatbot-with-FastAPI-and-Memory

2ï¸âƒ£ Create Virtual Environment
bash
Copy code
python -m venv .venv

Activate it:
Windows (PowerShell):
bash
Copy code
.venv\Scripts\activate

Linux/Mac:
bash
Copy code
source .venv/bin/activate

3ï¸âƒ£ Install Dependencies
bash
Copy code
pip install -r requirements.txt

4ï¸âƒ£ Setup Environment Variables
Create a .env file in the project root:
ini
Copy code
API_KEY=your_api_key_here

---

â–¶ï¸ Running the Project
Start Backend (FastAPI)
bash
Copy code
cd Backend
uvicorn app:app --reload
Backend will run at â†’ http://127.0.0.1:8000

Start Frontend (Streamlit)
bash
Copy code
cd Frontend
streamlit run frontend.py
Frontend will run at â†’ http://localhost:8501

---

ğŸ“¡ API Endpoints
1. Chat Endpoint
POST /chat

Request Body:
json
Copy code
{
  "session_id": "123",
  "message": "Hello!"
}

Response:
json
Copy code
{
  "response": "Hi! How can I help you today?",
  "history": [
    {"user": "Hello!", "bot": "Hi! How can I help you today?"}
  ]
}

2. Health Check
GET /health
Response:
json
Copy code
{"status": "ok"}

---

ğŸ§  Memory Management
Each user has a session_id that keeps track of conversation history.
The memory.py file stores messages in a dictionary:

python
Copy code
{
  "123": [
    {"user": "Hello", "bot": "Hi there!"},
    {"user": "Tell me a joke", "bot": "Why donâ€™t skeletons fight? They donâ€™t have guts."}
  ]
}
This makes the chatbot context-aware.

---

ğŸ“¸ Demo Preview
Backend running on FastAPI
Frontend with Streamlit simple chat UI

---

ğŸ“Œ Future Improvements
âœ… Add database support for persistent memory (Redis/Postgres).
âœ… Enhance UI (Gradio/React frontend).
âœ… Multi-user memory handling with authentication.
âœ… Support for multiple LLMs (OpenAI, Groq, Anthropic).

---

ğŸ¤ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss.

---

ğŸ“œ License
This project is licensed under the MIT License.
