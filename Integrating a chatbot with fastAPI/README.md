ğŸ¤– Integrating a Chatbot with FastAPI

This project demonstrates how to build and integrate a chatbot backend with FastAPI and a frontend using Streamlit. The chatbot uses Groq API (llama-3.1-8b-instant model) for real-time streaming responses.

ğŸ“‚ Project Structure
â”œâ”€â”€ app.py             # FastAPI backend (API endpoint for chatbot streaming)
â”œâ”€â”€ chatbot.py         # Chatbot logic (connects to Groq API)
â”œâ”€â”€ frontend.py        # Streamlit frontend interface
â”œâ”€â”€ requirements.txt   # Dependencies
â”œâ”€â”€ .env               # API keys and environment variables
â”œâ”€â”€ .gitignore         # Ignore venv, cache, and env files

âš™ï¸ Setup Instructions
1. Clone the repository
git clone https://github.com/your-username/fastapi-chatbot.git
cd fastapi-chatbot

2. Create and activate virtual environment
python -m venv .venv
# On Windows
.venv\Scripts\activate
# On Mac/Linux
source .venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

4. Configure environment variables

Create a .env file in the project root and add your Groq API key:

GROQ_API_KEY=your_api_key_here

(already included in .gitignore so it wonâ€™t be pushed to GitHub)

5. Run FastAPI backend
uvicorn app:app --reload

This will start the backend at:
ğŸ‘‰ http://127.0.0.1:8000/chat/stream

6. Run Streamlit frontend

In a new terminal (with venv activated):

streamlit run frontend.py

The frontend will open in your browser at:
ğŸ‘‰ http://localhost:8501

ğŸ›  How It Works

chatbot.py: Connects to Groq API and streams responses token-by-token.

app.py: Provides a FastAPI endpoint (/chat/stream) that streams chatbot replies.

frontend.py: A Streamlit-based UI where users can chat with the bot in real-time.

ğŸ“¦ Dependencies

All dependencies are listed in requirements.txt:

fastapi + uvicorn â†’ Backend API

streamlit â†’ Frontend UI

requests â†’ Streaming response handling in frontend

groq â†’ Groq API client

python-dotenv â†’ Load environment variables

ğŸš€ Demo

User enters a message in Streamlit chat UI.

The message is sent to FastAPI backend.

FastAPI streams the Groq modelâ€™s response back to frontend.

Streamlit displays the response incrementally in real-time.

ğŸ”’ Security

.env file is ignored via .gitignore to keep API keys safe.

Do not expose your GROQ_API_KEY in public repos.

ğŸ“œ License

This project is open-source and available under the MIT License.
